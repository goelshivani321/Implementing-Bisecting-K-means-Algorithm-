{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# open docs file and read its lines\n",
    "with open(\"../data/raw/train.dat\", \"r\") as fh:\n",
    "    lines = fh.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8580"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csr_read(fname, ftype=\"csr\", nidx=1):\n",
    "    \n",
    "    with open(fname) as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    if ftype == \"clu\":\n",
    "        p = lines[0].split()\n",
    "        nrows = int(p[0])\n",
    "        ncols = int(p[1])\n",
    "        nnz = long(p[2])\n",
    "        lines = lines[1:]\n",
    "        assert(len(lines) == nrows)\n",
    "    elif ftype == \"csr\":\n",
    "        nrows = len(lines)\n",
    "        ncols = 0 \n",
    "        nnz = 0 \n",
    "        for i in range(nrows):\n",
    "            p = lines[i].split()\n",
    "            if len(p) % 2 != 0:\n",
    "                raise ValueError(\"Invalid CSR matrix. Row %d contains %d numbers.\" % (i, len(p)))\n",
    "            nnz += len(p)//2\n",
    "            for j in range(0, len(p), 2): \n",
    "                cid = int(p[j]) - nidx\n",
    "                if cid+1 > ncols:\n",
    "                    ncols = cid+1\n",
    "    else:\n",
    "        raise ValueError(\"Invalid sparse matrix ftype '%s'.\" % ftype)\n",
    "    val = np.zeros(nnz, dtype=np.float)\n",
    "    ind = np.zeros(nnz, dtype=np.int)\n",
    "    ptr = np.zeros(nrows+1, dtype=np.long)\n",
    "    n = 0 \n",
    "    for i in range(nrows):\n",
    "        p = lines[i].split()\n",
    "        for j in range(0, len(p), 2): \n",
    "            ind[n] = int(p[j]) - nidx\n",
    "            val[n] = float(p[j+1])\n",
    "            n += 1\n",
    "        ptr[i+1] = n \n",
    "    \n",
    "    assert(n == nnz)\n",
    "    \n",
    "    return csr_matrix((val, ind, ptr), shape=(nrows, ncols), dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8580, 126355)\n"
     ]
    }
   ],
   "source": [
    "csr_mat = csr_read(\"../data/raw/train.dat\")\n",
    "print (csr_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csr_idf(matrix, copy=False, **kargs):\n",
    "    r\"\"\" Scale a CSR matrix by idf. \n",
    "    Returns scaling factors as dict. If copy is True, \n",
    "    returns scaled matrix and scaling factors.\n",
    "    \"\"\"\n",
    "    if copy is True:\n",
    "        matrix = matrix.copy()\n",
    "    nrows = matrix.shape[0]\n",
    "    nnz = matrix.nnz\n",
    "    ind, val, ptr = matrix.indices, matrix.data, matrix.indptr\n",
    "    # document frequency\n",
    "    df = defaultdict(int)\n",
    "    for i in ind:\n",
    "        df[i] += 1\n",
    "    # inverse document frequency\n",
    "    for k,v in df.items():\n",
    "        df[k] = np.log(nrows / float(v))  ## df turns to idf - reusing memory\n",
    "    # scale by idf\n",
    "    for i in range(0, nnz):\n",
    "        val[i] *= df[ind[i]]\n",
    "        \n",
    "    return df if copy is False else matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csr_l2normalize(matrix, copy=False, **kargs):\n",
    "    r\"\"\" Normalize the rows of a CSR matrix by their L-2 norm. \n",
    "    If copy is True, returns a copy of the normalized matrix.\n",
    "    \"\"\"\n",
    "    if copy is True:\n",
    "        matrix = matrix.copy()\n",
    "    nrows = matrix.shape[0]\n",
    "    nnz = matrix.nnz\n",
    "    ind, val, ptr = matrix.indices, matrix.data, matrix.indptr\n",
    "    # normalize\n",
    "    for i in range(nrows):\n",
    "        rsum = 0.0    \n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            rsum += val[j]**2\n",
    "        if rsum == 0.0:\n",
    "            continue  # do not normalize empty rows\n",
    "        rsum = float(1.0/np.sqrt(rsum))\n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            val[j] *= rsum\n",
    "            \n",
    "    if copy is True:\n",
    "        return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialCentroids(matrix):\n",
    "    matrixShuffled = shuffle(matrix, random_state=0)\n",
    "    return matrixShuffled[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarity(matrix, centroids):\n",
    "    similarities = matrix.dot(centroids.T)\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findClusters(matrix, centroids):\n",
    "    \n",
    "    clusterA = list()\n",
    "    clusterB = list()\n",
    "    \n",
    "    similarityMatrix = similarity(matrix, centroids)\n",
    "    \n",
    "    for index in range(similarityMatrix.shape[0]):\n",
    "        similarityRow = similarityMatrix[index]\n",
    "        \n",
    "        #Sort the index of the matrix in ascending order of value and get the index of the last element\n",
    "        #This index will be the cluster that the row in input matrix will belong to\n",
    "        similaritySorted = np.argsort(similarityRow)[-1]\n",
    "        \n",
    "        if similaritySorted == 0:\n",
    "            clusterA.append(index)\n",
    "        else:\n",
    "            clusterB.append(index)\n",
    "        \n",
    "    return clusterA, clusterB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recalculateCentroid(matrix, clusters):\n",
    "    centroids = list()\n",
    "    \n",
    "    for i in range(0,2):\n",
    "        cluster = matrix[clusters[i],:]\n",
    "        clusterMean = cluster.mean(0)\n",
    "        centroids.append(clusterMean)\n",
    "        \n",
    "    centroids_array = np.asarray(centroids)\n",
    "    \n",
    "    return centroids_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmeans(matrix, numberOfIterations):\n",
    "    \n",
    "    centroids = initialCentroids(matrix)\n",
    "    \n",
    "    for _ in range(numberOfIterations):\n",
    "        \n",
    "        clusters = list()\n",
    "        \n",
    "        clusterA, clusterB = findClusters(matrix, centroids)\n",
    "        \n",
    "        if len(clusterA) > 1:\n",
    "            clusters.append(clusterA)\n",
    "        if len(clusterB) > 1:\n",
    "            clusters.append(clusterB)\n",
    "            \n",
    "        centroids = recalculateCentroid(matrix, clusters)\n",
    "        \n",
    "    return clusterA, clusterB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateSSE(matrix, clusters):\n",
    "    \n",
    "    SSE_list = list()\n",
    "    SSE_array = []\n",
    "    \n",
    "    for cluster in clusters:\n",
    "        members = matrix[cluster,:]\n",
    "        SSE = np.sum(np.square(members - np.mean(members)))\n",
    "        SSE_list.append(SSE)\n",
    "        \n",
    "    SSE_array = np.asarray(SSE_list)\n",
    "    dropClusterIndex = np.argsort(SSE_array)[-1]\n",
    "            \n",
    "    return dropClusterIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bisecting_kmeans(matrix, k, numberOfIterations):\n",
    "    \n",
    "    clusters = list()\n",
    "    \n",
    "    initialcluster = list()\n",
    "    for i in range(matrix.shape[0]):\n",
    "        initialcluster.append(i)\n",
    "    \n",
    "    clusters.append(initialcluster)\n",
    "    \n",
    "    while len(clusters) < k:\n",
    "\n",
    "        dropClusterIndex = calculateSSE(matrix, clusters)\n",
    "        droppedCluster = clusters[dropClusterIndex]\n",
    "        \n",
    "        clusterA, clusterB = kmeans(matrix[droppedCluster,:], numberOfIterations)\n",
    "        del clusters[dropClusterIndex]\n",
    "        \n",
    "        actualClusterA = list()\n",
    "        actualClusterB = list()\n",
    "        for index in clusterA:\n",
    "            actualClusterA.append(droppedCluster[index])\n",
    "            \n",
    "        for index in clusterB:\n",
    "            actualClusterB.append(droppedCluster[index])\n",
    "        \n",
    "        clusters.append(actualClusterA)\n",
    "        clusters.append(actualClusterB)\n",
    "    \n",
    "    labels = [0] * matrix.shape[0]\n",
    "\n",
    "    for index, cluster in enumerate(clusters):\n",
    "        for idx in cluster:\n",
    "            labels[idx] = index + 1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read CSR matrix from the input file\n",
    "csrMatrix = csr_read('../data/raw/train.dat', ftype=\"csr\", nidx=1)\n",
    "\n",
    "#Scale the CSR matrix by idf (Inverse Document Frequency)\n",
    "csrIDF = csr_idf(csrMatrix, copy=True)\n",
    "\n",
    "#Normalize the rows of a CSR matrix by their L-2 norm.\n",
    "csrL2Normalized = csr_l2normalize(csrIDF, copy=True)\n",
    "\n",
    "#Obtain a dense ndarray representation of the CSR matrix.\n",
    "denseMatrix = csrL2Normalized.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics import calinski_harabaz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-54736c98e8f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m22\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbisecting_kmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenseMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m    \u001b[0;31m# if (k == 7):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-80282e895f03>\u001b[0m in \u001b[0;36mbisecting_kmeans\u001b[0;34m(matrix, k, numberOfIterations)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdroppedCluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdropClusterIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mclusterA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclusterB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdroppedCluster\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumberOfIterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdropClusterIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-18861a692f39>\u001b[0m in \u001b[0;36mkmeans\u001b[0;34m(matrix, numberOfIterations)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mclusters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusterB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecalculateCentroid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclusterA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclusterB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-fe2c13bd8c09>\u001b[0m in \u001b[0;36mrecalculateCentroid\u001b[0;34m(matrix, clusters)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mcluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mclusterMean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mcentroids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusterMean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kValues = list()\n",
    "scores = list()\n",
    "\n",
    "for k in range(3, 22, 2):\n",
    "    labels = bisecting_kmeans(denseMatrix, k, 10)\n",
    "    \n",
    "   # if (k == 7):\n",
    "        # write result to output file\n",
    "       # outputFile = open(\"output.dat\", \"w\")\n",
    "       # for index in labels:\n",
    "        #    outputFile.write(str(index) +'\\n')\n",
    "        #outputFile.close()\n",
    "\n",
    "    score = normalized_mutual_info_score(denseMatrix, labels)\n",
    "    kValues.append(k)\n",
    "    scores.append(score)\n",
    "    \n",
    "    print (\"For K= %d NMI is %f\" %(k, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = bisecting_kmeans(denseMatrix, 7, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amangal/anaconda3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "labels_true must be 1D: shape is (8580, 126355)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-a5260f9b47f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalized_mutual_info_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenseMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py\u001b[0m in \u001b[0;36mnormalized_mutual_info_score\u001b[0;34m(labels_true, labels_pred, average_method)\u001b[0m\n\u001b[1;32m    844\u001b[0m                       FutureWarning)\n\u001b[1;32m    845\u001b[0m         \u001b[0maverage_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'geometric'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m     \u001b[0mlabels_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_clusterings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/cluster/supervised.py\u001b[0m in \u001b[0;36mcheck_clusterings\u001b[0;34m(labels_true, labels_pred)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         raise ValueError(\n\u001b[0;32m---> 53\u001b[0;31m             \"labels_true must be 1D: shape is %r\" % (labels_true.shape,))\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: labels_true must be 1D: shape is (8580, 126355)"
     ]
    }
   ],
   "source": [
    "score = normalized_mutual_info_score(denseMatrix, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8580"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.035432919341474"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calinski_harabaz_score(denseMatrix, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csrMatrix = csr_read('../data/raw/train.dat', ftype=\"csr\", nidx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(csrMatrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>126345</th>\n",
       "      <th>126346</th>\n",
       "      <th>126347</th>\n",
       "      <th>126348</th>\n",
       "      <th>126349</th>\n",
       "      <th>126350</th>\n",
       "      <th>126351</th>\n",
       "      <th>126352</th>\n",
       "      <th>126353</th>\n",
       "      <th>126354</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 126355 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0       1       2       3       4       5       6       7       8       \\\n",
       "0     0.0     0.0     0.0     3.0     0.0     1.0     0.0     0.0     0.0   \n",
       "1     0.0     0.0     0.0     0.0     1.0     2.0     0.0     0.0     5.0   \n",
       "2     0.0     0.0     0.0     0.0     0.0     5.0     0.0     0.0     1.0   \n",
       "3     0.0     0.0     0.0     0.0     0.0     1.0     0.0     0.0     5.0   \n",
       "4     0.0     0.0     1.0     1.0     2.0     2.0     0.0     0.0     4.0   \n",
       "\n",
       "   9        ...    126345  126346  126347  126348  126349  126350  126351  \\\n",
       "0     0.0   ...       0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1     0.0   ...       0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2     0.0   ...       0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3     0.0   ...       0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4     0.0   ...       0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   126352  126353  126354  \n",
       "0     0.0     0.0     0.0  \n",
       "1     0.0     0.0     0.0  \n",
       "2     0.0     0.0     0.0  \n",
       "3     0.0     0.0     0.0  \n",
       "4     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 126355 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/predictions/1.0-sm-initial-eda.dat', 'w') as f:\n",
    "    for item in labels:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TerminalIPythonApp] WARNING | Subcommand `ipython nbconvert` is deprecated and will be removed in future versions.\n",
      "[TerminalIPythonApp] WARNING | You likely want to use `jupyter nbconvert` in the future\n",
      "[NbConvertApp] Converting notebook 1.0-sm-initial-eda.ipynb to python\n",
      "[NbConvertApp] Writing 8107 bytes to 1.0-sm-initial-eda.py\n"
     ]
    }
   ],
   "source": [
    "!ipython nbconvert --to=python 1.0-sm-initial-eda.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
